{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06f8f821-474b-46a0-a683-d0165f34067d",
   "metadata": {},
   "source": [
    "# 00 Combined RE and ARIMA Server_tA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6c3df9-4136-4032-bea2-08a50ac1d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install yfinance\n",
    "# !pip install anvil-uplink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ec5276-aad2-4052-9691-a183e725c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from zCreds import creds\n",
    "import anvil.server\n",
    "anvil.server.connect(creds['anvil'])\n",
    "import numpy as np\n",
    "from Collaborative_Filtering import Euclidian_Similarity, Recommendations\n",
    "from pandas.tseries.offsets import BDay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835bf929-284b-487b-bcd1-b94343005acb",
   "metadata": {},
   "source": [
    "# Global Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2131e7-a70a-40dd-80b8-da35f00a0036",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_funds        = pd.DataFrame()\n",
    "df_user_data    = pd.DataFrame()\n",
    "df_user_profile = pd.DataFrame()\n",
    "df_item_profile = pd.DataFrame()\n",
    "user_eu_sim_df  = pd.DataFrame()\n",
    "item_eu_sim_df  = pd.DataFrame()\n",
    "user_is_new = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cbe0e2-58ca-4dd4-80e4-409255d0e66e",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02108d2e-acca-4bb6-84bb-060cc8457633",
   "metadata": {},
   "source": [
    "##### Recommendation Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9091b99-6b26-4ed1-add5-fb8981894255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lu_funds():\n",
    "    global df_funds\n",
    "    df_funds = pd.read_csv('data/lu_funds.csv')\n",
    "    df_funds.set_index('fund_id', inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50da6068-9ac3-4cfa-8132-e6677af822d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_user_data():\n",
    "    global df_user_data\n",
    "    df_user_data = pd.read_csv('data/user_data.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa03ce-5883-489d-97f2-074dba373c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_existing_user_profiles():\n",
    "    global df_user_data\n",
    "    global df_user_profile\n",
    "    df_user_profile = df_user_data[['user_id','risk_appetite','investment_objective',\n",
    "                                'equities_alloc','bonds_alloc']].copy()\n",
    "    df_user_profile.set_index('user_id', inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e73546-92f8-48ed-ac0e-2124ad5287ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform feature scaling\n",
    "def numeric_df_min_max_scaling(df):\n",
    "    df = df.copy()\n",
    "    cols = df.columns.to_list()\n",
    "    for col in cols:\n",
    "        col_min = df[col].min()\n",
    "        col_max = df[col].max()\n",
    "        df[col] = (df[col]-col_min)/(col_max-col_min)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b542d66-a061-4e05-9767-dfc876f7a64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_user_based_eu_sim():\n",
    "    global user_eu_sim_df\n",
    "    user_eu_sim = Euclidian_Similarity(df_user_profile, verbose=0)\n",
    "    user_eu_sim_df = user_eu_sim.get_sim_scores_df()  # get the similarity scores matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061dcc81-a45a-4e43-bee8-79a32e1d9b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_df_item_profile():    \n",
    "    global df_user_data\n",
    "    global df_item_profile\n",
    "    \n",
    "    # create df_Item_profile, this is also used in 'item-based' collaborative filtering\n",
    "    zz = df_user_data[['fund_id' ,'user_id','user_satisfaction']].copy()\n",
    "    zz.set_index('user_id',inplace=True)\n",
    "\n",
    "    col_lbls = zz.fund_id.unique()\n",
    "    col_lbls= col_lbls[~pd.isnull(col_lbls)]\n",
    "\n",
    "    index_lbls = sorted(zz.index.to_list())\n",
    "\n",
    "    df_item_profile = pd.DataFrame(index=index_lbls, columns=col_lbls)\n",
    "\n",
    "    for uid,row in zz.iterrows():            \n",
    "        fid = zz.loc[uid,'fund_id']\n",
    "        if pd.isnull(fid):\n",
    "            continue\n",
    "        cust_sat = zz.loc[uid,'user_satisfaction']    \n",
    "        df_item_profile.loc[uid,fid] = cust_sat   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bc64f5-5a32-45dc-a273-e6cbc963e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_item_based_eu_sim():\n",
    "    global item_eu_sim_df    \n",
    "    item_eu_sim = Euclidian_Similarity(df_item_profile.T, verbose=0)  # note the transpose ('items' in rows,'users' in cols)\n",
    "    item_eu_sim_df = item_eu_sim.get_sim_scores_df()  # get the similarity scores matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d835f58-be85-4a4a-8407-da94d75ca914",
   "metadata": {},
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "def add_new_user_to_user_profiles(data):\n",
    "    \"\"\"\n",
    "    input: \n",
    "    data = {\n",
    "        'user_id': ['uid_101'],\n",
    "        'risk_appetite': [1],\n",
    "        'investment_objective':  [1],\n",
    "        'equities_alloc':  [50],\n",
    "        'bonds_alloc': [50]\n",
    "    }\n",
    "    \"\"\"\n",
    "    global df_user_data\n",
    "    global df_user_profile\n",
    "    \n",
    "    new_user_df = pd.DataFrame(data)\n",
    "    new_user_df.set_index('user_id',inplace=True)\n",
    "    \n",
    "    # insert the user details into df_user_profile as new or replace if exists\n",
    "    try:\n",
    "        # df_user_profile is a temp df used for calculating similarity\n",
    "        df_user_profile.loc[new_user_df.index[0],'risk_appetite'] = new_user_df['risk_appetite'][0]    \n",
    "        df_user_profile.loc[new_user_df.index[0],'investment_objective'] = new_user_df['investment_objective'][0]    \n",
    "        df_user_profile.loc[new_user_df.index[0],'equities_alloc'] = new_user_df['equities_alloc'][0]    \n",
    "        df_user_profile.loc[new_user_df.index[0],'bonds_alloc'] = new_user_df['bonds_alloc'][0]  \n",
    "\n",
    "        # df_user_data is permanent storage for users' data\n",
    "        df_user_data.set_index('user_id',inplace=True)\n",
    "        df_user_data.loc[new_user_df.index[0],'risk_appetite'] = new_user_df['risk_appetite'][0]    \n",
    "        df_user_data.loc[new_user_df.index[0],'investment_objective'] = new_user_df['investment_objective'][0]    \n",
    "        df_user_data.loc[new_user_df.index[0],'equities_alloc'] = new_user_df['equities_alloc'][0]    \n",
    "        df_user_data.loc[new_user_df.index[0],'bonds_alloc'] = new_user_df['bonds_alloc'][0]  \n",
    "        df_user_data.reset_index(inplace=True)\n",
    "\n",
    "    except KeyError:        \n",
    "        # # df_user_profile is a temp df used for calculating similarity        \n",
    "        # key does not exist, so we append the new user_id\n",
    "        df_user_profile = df_user_profile.append(new_user_df, ignore_index = False)   \n",
    "        \n",
    "        # df_user_data is permanent storage for users' data\n",
    "        df_user_data.set_index('user_id',inplace=True)\n",
    "        df_user_data = df_user_data.append(new_user_df, ignore_index = False)\n",
    "        df_user_data.reset_index(inplace=True)\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # min_max scale\n",
    "    # scale data\n",
    "    df_user_profile = numeric_df_min_max_scaling(df_user_profile)   \n",
    "    \n",
    "    # unless we load the stored user_based_eu_sim from disk, we always have to calculate\n",
    "    # regardless of new or existing user_id (for future optimisation)\n",
    "    calc_user_based_eu_sim()\n",
    "        \n",
    "    calc_df_item_profile()  # uid_101 needs this\n",
    "    \n",
    "    \n",
    "    # print(new_user_df.index[0]) # display uid\n",
    "    rec_dict = given_user_recommend_item(new_user_df.index[0])\n",
    "    \n",
    "    return rec_dict\n",
    "    \n",
    "# return user_eu_sim_df.iloc[0,10]\n",
    "# return new_user_df.reset_index(inplace=False).to_dict(orient='records')\n",
    "# return df_user_profile.reset_index(inplace=False).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62255f6d-690b-4c8c-a743-a20c7812636f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "def given_user_recommend_item(uid):\n",
    "    \"\"\"\n",
    "    uid must already have been added via add_new_user_to_user_profiles()\n",
    "    \n",
    "    \"\"\"\n",
    "    user_id = uid\n",
    "    rec = Recommendations(user_id, df_item_profile, user_eu_sim_df, verbose=0)\n",
    "\n",
    "    threshold = 3\n",
    "    top_k=3\n",
    "    df_rec, rec_lst = rec.get_recommendations(threshold=threshold, top_k=top_k)\n",
    "    \n",
    "    investment_returns_lst = []\n",
    "    for fund_id in rec_lst:\n",
    "        #investment_returns_lst.append(df_user_data[df_user_data.fund_id == fund_id].investment_return.mean().round(2))\n",
    "        investment_returns_lst.append(df_user_data[df_user_data.fund_id == fund_id].investment_return.mean())\n",
    "\n",
    "    data = {'fund_id': rec_lst,'investment_returns': investment_returns_lst}    \n",
    "    df_iReturns = pd.DataFrame(data)\n",
    "    df_iReturns.set_index('fund_id', inplace=True)\n",
    "    df_recs_to_return = pd.DataFrame()\n",
    "    df_recs_to_return = pd.concat([df_funds.loc[rec_lst,['fund_chosen']], df_rec['recommendation_score']],axis=1)\n",
    "    df_recs_to_return = pd.concat([df_recs_to_return,df_iReturns[['investment_returns']]],axis=1) \n",
    "\n",
    "    # display(df_recs_to_return)\n",
    "    return df_recs_to_return.reset_index(inplace=False).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9330f39-98cb-4f4c-bed3-6aa3402ce5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "def given_item_recommend_item(fid='fid_1'):\n",
    "    \"\"\"\n",
    "    uid: string, user id\n",
    "        uid must already have been added via add_new_user_to_user_profiles()\n",
    "        we use the default first uid as the 'ficticious user'\n",
    "    fid: string fund id\n",
    "         default: 'fid_1'\n",
    "         we need this because this is what the user selected in the App UI\n",
    "    \n",
    "    \"\"\"\n",
    "    # coz this is item-based, it doesn't matter which user_id it is, we just need to mark one uid\n",
    "    # so that the algorithm can return recommendations for a ficticious uid\n",
    "    # the recs are not stored. For future, if item-based similarities are scored, it is calculated\n",
    "    # from the actual user ratings, not from here.\n",
    "    user_id = 'uid_1'     \n",
    "    user_id_profile = df_item_profile.loc[[user_id],:].copy()\n",
    "    user_id_profile.loc[user_id, fid] = 2.5  # this is the fid user has select to display in the UI\n",
    "    # nb: it is NOT a rating, it's just selected, hence 2.5 is the mid-point from rating 1 to 5    \n",
    "    \n",
    "    rec = Recommendations(user_id, user_id_profile, item_eu_sim_df, cf_type='item', verbose=0)\n",
    "    \n",
    "    threshold = 3\n",
    "    top_k=1    \n",
    "    df_rec, rec_lst = rec.get_recommendations(threshold=0, top_k=top_k)\n",
    "    \n",
    "    investment_returns_lst = []\n",
    "    for fund_id in rec_lst:\n",
    "        investment_returns_lst.append(df_user_data[df_user_data.fund_id == fund_id].investment_return.mean())\n",
    "\n",
    "    data = {'fund_id': rec_lst,'investment_returns': investment_returns_lst}    \n",
    "    df_iReturns = pd.DataFrame(data)\n",
    "    df_iReturns.set_index('fund_id', inplace=True)\n",
    "    df_recs_to_return = pd.DataFrame()\n",
    "    df_recs_to_return = pd.concat([df_funds.loc[rec_lst,['fund_chosen']], df_rec['recommendation_score']],axis=1)\n",
    "    df_recs_to_return = pd.concat([df_recs_to_return,df_iReturns[['investment_returns']]],axis=1) \n",
    "\n",
    "    # display(df_recs_to_return)\n",
    "    return df_recs_to_return.reset_index(inplace=False).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04427c39-b000-409d-9f4e-6d06d305d49d",
   "metadata": {},
   "source": [
    "##### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51df5822-cae6-430f-82ce-2f161e3c2b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ticker(ticker, start_date, end_date, train_size=0.8):    \n",
    "    \n",
    "    # df = yf.download(ticker, start=start_date, end=end_date, group_by=\"ticker\")\n",
    "    \n",
    "    # https://stackoverflow.com/questions/67291926/remove-comment-from-yfinance\n",
    "    # stop progress bar\n",
    "    df = yf.download(ticker, start=start_date, end=end_date, group_by=\"ticker\",progress=False)\n",
    "    \n",
    "    df = df.asfreq('b')  # set frequency 'b' business day - Mon to Fri\n",
    "    \n",
    "    if df.isnull().sum().sum()>0:\n",
    "        df=df.fillna(method='ffill')\n",
    "    \n",
    "\n",
    "    # train_set_size = int(df.shape[0] * train_size) # if want train split\n",
    "    train_set_size = df.shape[0]  # take all rows, NO, train test split\n",
    "    X_train, X_test = df.iloc[:train_set_size], df.iloc[train_set_size:] \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f3f7b5-4794-481a-a9a3-8548d2017de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_arima_model(train_set, verbose=0):\n",
    "    model = sm.tsa.arima.ARIMA(train_set, order=(2,2,2))\n",
    "    results_model = model.fit()\n",
    "    if verbose>0:        \n",
    "        print(results_model.summary())\n",
    "    return results_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3a5d74-118c-4601-bef0-2c8f48a9fba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arima_predict(trained_model, start_date, forecast_date, verbose=0):\n",
    "    # nb: model must be fitted first before calling .predict()\n",
    "    forecast = trained_model.predict(start=start_date, end=forecast_date)  # returns a pandas series\n",
    "    if verbose>0:\n",
    "        print(type(forecast))\n",
    "        print()\n",
    "        print(forecast.head(3))\n",
    "        print()\n",
    "        print(forecast.tail(3))\n",
    "        print()    \n",
    "        print(forecast[-1:])\n",
    "        print()\n",
    "        print(forecast[-1:].index[0].strftime('%Y-%m-%d'))\n",
    "        print()\n",
    "        target_date = forecast[-1:].index[0].strftime('%Y-%m-%d')\n",
    "    \n",
    "    \n",
    "    #return forecast\n",
    "#     print('temp:')\n",
    "#     display(forecast.head())    \n",
    "    return forecast.reset_index(inplace=False).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429e6262-589e-4207-9084-cc5bae3cd4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "def arima_main(ticker='AAPL', ohlc='Adj Close', verbose=0):\n",
    "    \n",
    "    if verbose>0:\n",
    "        print('today:', datetime.now())\n",
    "    \n",
    "    start_date = datetime.now() - relativedelta(years=3)    # 3 years ago    \n",
    "    start_date = start_date - BDay(1)\n",
    "    start_date = start_date.strftime('%Y-%m-%d')\n",
    "    if verbose>0:\n",
    "        print('start_date', start_date)\n",
    "\n",
    "    end_date = datetime.now() - relativedelta(days=1)       # 1 day ago    \n",
    "    end_date = end_date - BDay(1)\n",
    "    end_date = end_date.strftime('%Y-%m-%d')     \n",
    "    if verbose>0:\n",
    "        print('end_date', end_date)\n",
    "\n",
    "    forecast_date = datetime.now() - relativedelta(days=1) + relativedelta(years=5) # 5 years from now\n",
    "    forecast_date = forecast_date - BDay(1)    \n",
    "    forecast_date = forecast_date.strftime('%Y-%m-%d')\n",
    "    if verbose>0:\n",
    "        print('forecast_date', forecast_date)\n",
    "\n",
    "    X_train, X_test = load_ticker(ticker, start_date, end_date)\n",
    "    # I think yfinance automatically skips public holidays in whatever market the ticker falls under, e.g. USA market\n",
    "    # hence, if the start_date I selected above is a PH, yFinance will not load it. Instead, it will load the next\n",
    "    # available business day. \n",
    "    # so the quickest fix is to take the earliest date AFTER yfinance loads the ticker data and then set my start_date\n",
    "    # to it, so that when calling ._predict() the start date will match.\n",
    "\n",
    "    if verbose>0:\n",
    "        print('\\n\\nstart date_initial:\\t', start_date)\n",
    "        print('X_train starting date:\\t', X_train.index[0].strftime('%Y-%m-%d'))       \n",
    "        \n",
    "    start_date = X_train.index[0].strftime('%Y-%m-%d')\n",
    "    end_date = X_train.index[-1].strftime('%Y-%m-%d')\n",
    "        \n",
    "    if verbose>0:\n",
    "        print('start date_after using X_train starting date:', start_date)\n",
    "        print()\n",
    "    \n",
    "    X_train = X_train[ohlc]\n",
    "    X_test  = X_test[ohlc] \n",
    "    if verbose>0:\n",
    "        print('\\n','X_train.shape:', X_train.shape, 'X_test.shape:',X_test.shape,'\\n')    \n",
    "        print('X_train.head()')\n",
    "        display(X_train.head(3))\n",
    "        print()\n",
    "        print('X_test.head()')\n",
    "        display(X_test.head(3))        \n",
    "    \n",
    "    if verbose>0:\n",
    "        print('\\nBEFORE exec \"train_arima_model()\"')\n",
    "    results_ar_1_i_1_ma_1 = train_arima_model(X_train, verbose=verbose)\n",
    "    if verbose>0:\n",
    "        print('AFTER exec \"train_arima_model()\"','\\n')\n",
    "\n",
    "    # forecast date may also be a PH, so need to ensure it is a business day and NOT a PH??\n",
    "    # so far no error, but something to look out for, maybe?    \n",
    "    forecast = arima_predict(results_ar_1_i_1_ma_1, start_date, forecast_date, verbose=verbose)\n",
    "    \n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2594453f-d6e0-4622-b8e9-af167202920d",
   "metadata": {},
   "source": [
    "##### Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048e6460-2cb4-49a6-928a-592d8cd427fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "def hello(name, msg):\n",
    "    msg = 'From HW_laptop: hello {}, this is your msg: {}. Time is: {}'.format(name,msg, datetime.now())\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8c1d8b-c275-40c2-a0d2-f2d3f4fab44f",
   "metadata": {},
   "source": [
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d310927-752b-484b-9741-ad6f23a0a90e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Recommendation Engine : must run these to load into globals\n",
    "load_lu_funds()\n",
    "load_user_data()\n",
    "prep_existing_user_profiles()\n",
    "\n",
    "# since this is based on existing user_data, can precalc?\n",
    "calc_df_item_profile()\n",
    "calc_item_based_eu_sim()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc6cae8-5a24-4808-934d-9fb630caf166",
   "metadata": {},
   "source": [
    "# Offline Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deba7df8-ae70-4ea7-a4a2-caa3e3ea0eb6",
   "metadata": {},
   "source": [
    "##### Recommendation Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f004f542-acec-426f-9088-3322b56d98b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Offine Testing: Comment out if not in use\n",
    "# #Given User, Recommend one or more Items\n",
    "\n",
    "# user_id = 'uid_72'  \n",
    "# user_id = 'uid_101'  \n",
    "\n",
    "# data = {\n",
    "#     'user_id': [user_id],\n",
    "#     'risk_appetite': [1],\n",
    "#     'investment_objective':  [1],\n",
    "#     'equities_alloc':  [50],\n",
    "#     'bonds_alloc': [50]\n",
    "# }\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# result = add_new_user_to_user_profiles(df)\n",
    "# display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b98c96c-629c-4cdd-b41d-8725416b5e20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Given Item, recommend one or more items\n",
    "\n",
    "# fid = 'fid_1'\n",
    "# result = given_item_recommend_item(fid=fid)\n",
    "# result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c80318f-15b8-4e37-992c-810c1e81af45",
   "metadata": {},
   "source": [
    "##### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4325d09a-fafd-48cc-97d4-18e4f5867423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Offine Testing: Comment out if not in use\n",
    "# ticker = \"AAPL\"\n",
    "# forecast = arima_main(ticker, verbose=0)\n",
    "\n",
    "# print(forecast[0])\n",
    "# print(forecast[0]['index'].strftime('%Y-%m-%d'))\n",
    "# print(round(forecast[0]['predicted_mean'],2))\n",
    "# print()\n",
    "# print(forecast[-1])\n",
    "# print(forecast[-1]['index'].strftime('%Y-%m-%d'))\n",
    "# print(round(forecast[-1]['predicted_mean'],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b4594a-976c-462e-ae45-bee3e69d56e2",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41faa33c-0909-4282-ae67-32505ec1220d",
   "metadata": {},
   "source": [
    "# Start Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c15c9cb-9526-4c5a-bf6d-ce16adc65b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Online Server, comment out if doing off-line test\n",
    "anvil.server.wait_forever()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
